# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
load.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0015, minsplit=30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# This is pretty blocky
# let's fit a bigger tree
load.tree2 = rpart(COAST~temp + dewpoint, data=load_tree,
control = rpart.control(cp = 0.00001))
# cross-validated error plot.
# the result is VERY typical of tree models:
# an initial sharp drop followed by a long flat plateau and then a slow rise.
plotcp(load.tree2)
rpart.plot(load.tree2, digits=-5, type=4, extra=1)
# small tree
load.tree2 = rpart(COAST~temp + dewpoint, data=load_tree,
control = rpart.control(cp = 0.0015))
rpart.plot(load.tree2, digits=-5, type=4, extra=1)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
load.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0015))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
load.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.01))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
load.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
load.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(load.tree)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(dengue.tree, ylim=c(0.26, 0.28))
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(load.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(dengue.tree, ylim=c(0.26, 0.28))
# you could squint at the table...
printcp(dengue.tree)
# plot tree and implied partition in 2D x space.
load_tree = load_tree %>%
mutate(COAST_pred2 = predict(load.tree2)) %>%
arrange(temp)
ggplot(load_tree) +
geom_point(aes(x=temp, y=dewpoint, color=COAST_pred2)) +
scale_color_continuous(type = "viridis")
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(dengue.tree, ylim=c(0.26, 0.28))
# you could squint at the table...
printcp(dengue.tree)
# now plot the fit over the original data
ggplot(load_tree) +
geom_point(aes(x=temp, y=COAST), alpha=0.1) +
geom_step(aes(x=temp, y=COAST_pred), color='red', size=2)
# plot tree and implied partition in 2D x space.
dengue_train = dengue_train %>%
mutate(case_predict = predict(dengue_train)) %>%
arrange(temp)
# plot tree and implied partition in 2D x space.
dengue_train = dengue_train %>%
mutate(case_predict = predict(dengue_train)) %>%
arrange(tdtr_k)
# plot tree and implied partition in 2D x space.
dengue_train = dengue_train %>%
mutate(case_predict = predict(dengue.tree)) %>%
arrange(tdtr_k)
ggplot(dengue_train) +
geom_point(aes(x=tdtr_k, y=precipitation_amt, color=total_cases)) +
scale_color_continuous(type = "viridis")
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~specific_humidity + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 30))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
ggplot(dengue_train) +
geom_point(aes(x=specific_humidity, y=precipitation_amt, color=total_cases)) +
scale_color_continuous(type = "viridis")
# plot tree and implied partition in 2D x space.
dengue_train = dengue_train %>%
mutate(case_predict = predict(dengue.tree)) %>%
arrange(specific_humidity)
rpart.plot(load.tree2, digits=-5, type=4, extra=1)
# small tree
load.tree2 = rpart(COAST~temp + dewpoint, data=load_tree,
control = rpart.control(cp = 0.0015))
rpart.plot(load.tree2, digits=-5, type=4, extra=1)
# plot tree and implied partition in 2D x space.
load_tree = load_tree %>%
mutate(COAST_pred2 = predict(load.tree2)) %>%
arrange(temp)
ggplot(load_tree) +
geom_point(aes(x=temp, y=dewpoint, color=COAST_pred2)) +
scale_color_continuous(type = "viridis")
# This is pretty blocky
# let's fit a bigger tree
load.tree2 = rpart(COAST~temp + dewpoint, data=load_tree,
control = rpart.control(cp = 0.00001))
# plot tree and implied partition in 2D x space.
load_tree = load_tree %>%
mutate(COAST_pred2 = predict(load.tree2)) %>%
arrange(temp)
ggplot(load_tree) +
geom_point(aes(x=temp, y=dewpoint, color=COAST_pred2)) +
scale_color_continuous(type = "viridis")
# plot tree and implied partition in 2D x space.
dengue_train = dengue_train %>%
mutate(case_predict = predict(dengue.tree)) %>%
arrange(specific_humidity)
# cross-validated error plot.
plotcp(dengue.tree)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(dengue.tree, ylim=c(0.26, 0.28))
cp_1se(dengue.tree)
# a handy function for picking the smallest tree
# whose CV error is within 1 std err of the minimum
cp_1se = function(my_tree) {
out = as.data.frame(my_tree$cptable)
thresh = min(out$xerror + out$xstd)
cp_opt = max(out$CP[out$xerror <= thresh])
cp_opt
}
cp_1se(dengue.tree)
# you could squint at the table...
printcp(dengue.tree)
# let's prune our tree at the 1se complexity level
dengue.tree_prune = prune_1se(dengue.tree)
# this function actually prunes the tree at that level
prune_1se = function(my_tree) {
out = as.data.frame(my_tree$cptable)
thresh = min(out$xerror + out$xstd)
cp_opt = max(out$CP[out$xerror <= thresh])
prune(my_tree, cp=cp_opt)
}
# let's prune our tree at the 1se complexity level
dengue.tree_prune = prune_1se(dengue.tree)
#plot the tree
rpart.plot(dengue.tree_prune, type=4, digits=-5, extra=1, cex=0.5)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~city + season + specific_humidity + tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0001, minsplit = 5))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~city + season + specific_humidity + tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0001, minsplit = 10))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# you could squint at the table...
printcp(dengue.tree)
# picking the smallest tree whose CV error is within 1 std err of the minimum
cp_1se(dengue.tree)
# let's prune our tree at the 1se complexity level
dengue.tree_prune = prune_1se(dengue.tree)
#plot the tree
rpart.plot(dengue.tree_prune, type=4, digits=-5, extra=1, cex=0.5)
# cross-validated error plot.
plotcp(dengue.tree)
# cross-validated error plot.
# the result is VERY typical of tree models:
# an initial sharp drop followed by a long flat plateau and then a slow rise.
plotcp(load.tree2)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(load.tree2, ylim=c(0.26, 0.28))
# cross-validated error plot.
# the result is VERY typical of tree models:
# an initial sharp drop followed by a long flat plateau and then a slow rise.
plotcp(load.tree2)
# the vertical bars show the standard error of CV error across the 10 splits
plotcp(load.tree2, ylim=c(0.26, 0.28))
# cross-validated error plot.
plotcp(dengue.tree)
plotcp(load.tree2, ylim=c(0.8, 1.2))
plotcp(load.tree2, ylim=c(0.26, 0.28))
plotcp(dengue.tree, ylim=c(0.26, 0.28))
plotcp(dengue.tree, ylim=c(0.8, 1.2))
# cross-validated error plot.
plotcp(dengue.tree)
#plot the tree
rpart.plot(dengue.tree_prune, type=4, digits=-5, extra=1, cex=0.5)
# cross-validated error plot.
plotcp(dengue.tree_prune)
# you could squint at the table...
printcp(dengue.tree)
# you could squint at the table...
printcp(dengue.tree_prune)
# split into training and testing
train_frac = 0.8
N_train = floor(train_frac*N)
N = nrow(dengue)
# split into training and testing
train_frac = 0.8
N_train = floor(train_frac*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE) %>% sort
dengue_train = dengue[train_ind,]
dengue_test = dengue[-train_ind,]
# build a classification tree with variables indicated in questions
dengue_tree= rpart(total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt, data = dengue_train)
# plot the tree
rpart.plot(dengue_tree, type=4, extra=1)
# the various summaries of the tree
print(dengue_tree) # the structure
summary(dengue_tree)  # more detail on the splits
# in-sample fit, i.e. predict on the original training data
# this returns predicted class probabilities
predict(dengue_tree, newdata=dengue_train)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~city + season + specific_humidity + tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0001, minsplit = 10))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# you could squint at the table...
printcp(dengue.tree)
# picking the smallest tree whose CV error is within 1 std err of the minimum
cp_1se(dengue.tree)
# let's prune our tree at the 1se complexity level
dengue.tree_prune = prune_1se(dengue.tree)
#plot the tree
rpart.plot(dengue.tree_prune, type=4, digits=-5, extra=1, cex=0.5)
# you could squint at the table...
printcp(dengue.tree)
# in-sample fit, i.e. predict on the original training data
# this returns predicted class probabilities
predict(dengue_tree, newdata=dengue_train)
plotcp(dengue_tree)
printcp(dengue_tree)
cp_1se(dengue_tree)
summary(dengue_tree)  # more detail on the splits
# cross-validated error plot.
plotcp(dengue_tree)
# you could squint at the table...
printcp(dengue_tree)
# picking the smallest tree whose CV error is within 1 std err of the minimum
cp_1se(dengue_tree)
# in-sample fit, i.e. predict on the original training data
# this returns predicted class probabilities
predict(dengue_tree, newdata=dengue_train)
# you could squint at the table...
printcp(dengue.tree)
# cross-validated error plot.
plotcp(dengue.tree)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~city + season + specific_humidity + tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.002, minsplit = 10))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# you could squint at the table...
printcp(dengue.tree)
# picking the smallest tree whose CV error is within 1 std err of the minimum
cp_1se(dengue.tree)
# grow a smallish tree
# larger cp and insplit means stop at a smaller tree
dengue.tree = rpart(total_cases~city + season + specific_humidity + tdtr_k + precipitation_amt, data=dengue_train,
control = rpart.control(cp = 0.0002, minsplit = 10))
# plot the tree
# see ?rpart.plot for the various plotting options here (type, extra)
rpart.plot(dengue.tree, digits=-5, type=4, extra=1)
# cross-validated error plot.
plotcp(dengue.tree)
# you could squint at the table...
printcp(dengue.tree)
# picking the smallest tree whose CV error is within 1 std err of the minimum
cp_1se(dengue.tree)
# let's prune our tree at the 1se complexity level
dengue.tree_prune = prune_1se(dengue.tree)
#plot the tree
rpart.plot(dengue.tree_prune, type=4, digits=-5, extra=1, cex=0.5)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, mtry = 5, ntree=100)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, mtry = 5, ntree=100)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ city + season + specific_humidity + tdtr_k + precipitation_amt, data = dengue_train, mtry = 5, ntree=100)
source("C:/Users/Haokun Zhang/Desktop/UTexas classes/Data mining/data mining assignments/data-mining-assignments/ECO 395M Homework 3/ECO HW 3.R")
load_coast = read.csv('../data/load_coast.csv', row.names=1)
library(randomForest)
library(gbm)
load_coast = read.csv('../data/load_coast.csv', row.names=1)
N = nrow(load_coast)
# split into a training and testing set
train_frac = 0.8
N_train = floor(train_frac*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE) %>% sort
load_train = load_coast[train_ind,]
load_test = load_coast[-train_ind,]
# let's do bagging first
# average over 25 bootstrap samples
# use all candidate variables (mtry=15) in each bootstrapped sample
forest1 = randomForest(COAST ~ ., data = load_train, mtry = 15, ntree=25)
yhat_forest = predict(forest1, load_test)
rmse_forest = mean((yhat_forest - load_test$COAST)^2) %>% sqrt
# now true random forests
# now average over 100 bootstrap samples
# this time only 5 candidate variables (mtry=5) in each bootstrapped sample
forest2 = randomForest(COAST ~ ., data = load_train, mtry = 5, ntree=100)
yhat_forest2 = predict(forest2, load_test)
rmse_forest2 = mean((yhat_forest2 - load_test$COAST)^2) %>% sqrt
boost_ercot = gbm(COAST ~ ., data=load_train,
n.trees=500, shrinkage=.05)
yhat_forest = predict(forest1, load_test)
View(load_coast)
# now true random forests
# now average over 100 bootstrap samples
# this time only 5 candidate variables (mtry=5) in each bootstrapped sample
forest2 = randomForest(COAST ~ ., data = load_train, mtry = 5, ntree=100)
yhat_forest2 = predict(forest2, load_test)
rmse_forest2 = mean((yhat_forest2 - load_test$COAST)^2) %>% sqrt
boost_ercot = gbm(COAST ~ ., data=load_train,
n.trees=500, shrinkage=.05)
yhat_boost = predict(boost_ercot, load_test, n.trees=500)
rmse_boost = mean((yhat_boost - load_test$COAST)^2) %>% sqrt
rmse_boost
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, mtry = 5, ntree=100)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, mtry = 5, ntree=100, na.action = na.roughfix)
?rfImpute
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, na.action = na.roughfix, mtry = 5, ntree=100)
sapply(dengue_train, class)
source("C:/Users/Haokun Zhang/Desktop/UTexas classes/Data mining/data mining assignments/data-mining-assignments/ECO 395M Homework 3/ECO HW 3.R")
source("C:/Users/Haokun Zhang/Desktop/UTexas classes/Data mining/data mining assignments/data-mining-assignments/ECO 395M Homework 3/ECO HW 3.R")
sapply(dengue_train, class)
dengue$total_cases <- as.numeric(dengue$total_cases)
sapply(dengue_train, class)
View(dengue)
dengue$total_cases <- as.numeric(as.character(dengue$total_cases))
View(dengue)
sapply(dengue_train, class)
# split into training and testing
train_frac = 0.8
N_train = floor(train_frac*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE) %>% sort
dengue_train = dengue[train_ind,]
dengue_test = dengue[-train_ind,]
sapply((dengue_train, class))
sapply((dengue_train, class)
sapply(dengue_train, class)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, na.action = na.roughfix, mtry = 5, ntree=100)
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ . - season - city, data = dengue_train, na.action = na.roughfix, mtry = 5, ntree=100)
dengue$city <- as.factor(dengue$city)
sapply(dengue, class)
View(dengue)
dengue$season <- as.factor(dengue$season)
# split into training and testing
train_frac = 0.8
N_train = floor(train_frac*N)
N_test = N - N_train
train_ind = sample.int(N, N_train, replace=FALSE) %>% sort
dengue_train = dengue[train_ind,]
dengue_test = dengue[-train_ind,]
# random forests
# average over 100 bootstrap samples
# only 5 candidate variables (mtry=5) in each bootstrapped sample
dengue2 = randomForest(total_cases ~ ., data = dengue_train, na.action = na.roughfix, mtry = 5, ntree=100)
yhat_forest2 = predict(forest2, dengue_test)
yhat_forest2 = predict(dengue2, dengue_test)
yhat_dengue2 = predict(dengue2, dengue_test)
rmse_dengue2 = mean((yhat_dengue2 - dengue_test$total_cases)^2) %>% sqrt
boost_dengue = gbm(total_cases ~ ., data=dengue_train,
n.trees=500, shrinkage=.05)
yhat_boost = predict(boost_dengue, dengue_test, n.trees=500)
rmse_boost = mean((yhat_boost - dengue_test$total_cases)^2) %>% sqrt
rmse_boost
source("C:/Users/Haokun Zhang/Desktop/UTexas classes/Data mining/data mining assignments/data-mining-assignments/ECO 395M Homework 3/ECO HW 3.R")
knitr::opts_chunk$set(echo = TRUE)
cat("The average effect of green certification on the rent income is ", Diff_mean, "\n")
library(tidyverse)
library(tidyverse)
library(ggplot2)
library(rsample)
library(modelr)
library(ggplot2)
library(rsample)
library(modelr)
library(randomForest)
library(ggmap)
library(rpart)       #for fitting decision trees
library(ipred)       #for fitting bagged decision trees
Calihousing <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/CAhousing.csv")
# normalize two variables.
Calihousing$normal_Rooms <- ((Calihousing$totalRooms)/(Calihousing$households))
Calihousing$normal_Bedrooms <- ((Calihousing$totalBedrooms)/(Calihousing$households))
# Separate the dataset to spliting and testing data
CAhousing_split = initial_split(Calihousing, prop = 0.8)
CAhousing_training = training(CAhousing_split)
CAhousing_testing = testing(CAhousing_split)
# Separate the dataset to spliting and testing data
CAhousing_split = initial_split(Calihousing, prop = 0.8)
CAhousing_training = training(CAhousing_split)
CAhousing_testing = testing(CAhousing_split)
```{r,echo=FALSE, message= FALSE, warning=FALSE}
#  the Random Forest model
model_random_forest = randomForest(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training)
yhat_test_forest = predict(model_random_forest, CAhousing_testing)
plot(yhat_test_forest, CAhousing_testing$medianHouseValue)
rmse(model_random_forest, CAhousing_testing)
plot(model_random_forest)
#  the bagging model
model_bagging = bagging(formula = medianHouseValue ~ .-totalRooms-totalBedrooms,
data = CAhousing_training,
nbagg=150,coob=T,control = rpart.control(minsplit = 2, cp = 0))
model_CART = rpart(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training)
# the CART model
set.seed(1)
model_CART = rpart(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training)
```{r,echo=FALSE, message= FALSE, warning=FALSE}
# boosting model
set.seed(1)
model_boosting = gbm(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training,
interaction.depth=4, n.trees=400, shrinkage=.05)
model_CART = rpart(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training)
library(gbm)
model_boosting = gbm(medianHouseValue ~ .-totalRooms-totalBedrooms,
data=CAhousing_training,
interaction.depth=4, n.trees=400, shrinkage=.05)
# calculate the rmse of each model
rmse(model_random_forest, CAhousing_testing)
# calculate the rmse of each model
rmse(model_random_forest, CAhousing_testing)
rmse(model_bagging, CAhousing_testing)
rmse(model_CART, CAhousing_testing)
rmse(model_CART, CAhousing_testing)
rmse(model_boosting, CAhousing_testing)
