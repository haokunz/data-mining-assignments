p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) +
ylim(7000, 20000)
p_test
#knn to 350
knn15 = knnreg(price ~ mileage, data=trimAMG_train, k=15)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) +
ylim(7000, 20000)
p_test
# now add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
knn15 = knnreg(price ~ mileage, data=trimAMG_train, k=15)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
#ylim(7000, 20000)
p_test
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# plot means and std errors versus k
ggplot(cv_grid) +
geom_point(aes(x=k, y=err)) +
geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
scale_x_log10()
# knn to 350
knn15 = knnreg(price ~ mileage, data=trimAMG_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
#ylim(7000, 20000)
p_test
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
knn15 = knnreg(price ~ mileage, data=trimAMG_train, k=20)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
#ylim(7000, 20000)
p_test
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
knn15 = knnreg(price ~ mileage, data=trimAMG_train, k=15)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
#ylim(7000, 20000)
p_test
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=15)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=20)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
trimAMG_folds = crossv_kfold(trim_65_AMG,k=k_folds)
cv_gridAMG = foreach(k = k_grid, .combine='rbind') %dopar% {
# map the model-fitting function over the training sets
models = map(trimAMG_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
# map the RMSE calculation over the trained models and test sets simultaneously
errs = map2_dbl(models, trimAMG_folds$test, modelr::rmse)
c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds)) # approximate standard error of CV error
} %>% as.data.frame
head(cv_gridAMG)
# plot means and std errors versus k
ggplot(cv_gridAMG) +
geom_point(aes(x=k, y=err)) +
geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
scale_x_log10()
View(cv_gridAMG)
# knn to 350
knn20 = knnreg(price ~ mileage, data=trim350_train, k=20)
modelr::rmse(knn20, trimAMG_test)
# attach the predictions to the test data frame
trimAMG_test = trimAMG_test %>%
mutate(Price_pred = predict(knn20, trimAMG_test))
p_test = ggplot(data = trimAMG_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn20 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn20, trimAMG_test)
# attach the predictions to the test data frame
trimAMG_test = trimAMG_test %>%
mutate(Price_pred = predict(knn20, trimAMG_test))
p_test = ggplot(data = trimAMG_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(tidyverse)
library(data.table)
library(fixest)
library(bacondecomp)
library(TwoWayFEWeights)
library(fixest)
library(glue)
library(did)
library(data.table)
library(fixest)
library(caret)
library(tidyverse)
library(ggplot2)
library(glmnet)
library(gbm)
library(ggmap)
library(rpart)
library(rpart.plot)
library(randomForest)
library(rsample)
library(modelr)
library(fastDummies)
library(scales)
library(here)
library(knitr)
library(kableExtra)
library(stargazer)
library(haven)
library(here)
library(foreach)
path <- here()
state_crime = read.csv("data/UpdatedStateLevelData-2010.csv")
state_rollout = state_crime %>%
filter(year>=1977 & year<=1992)
treat_table = state_rollout %>%
group_by(state) %>%
summarize(cnt = sum(shalll)) %>%
na.omit()
state_rollout = left_join(state_rollout, treat_table, by = c("state" = "state"))
state_rollout = state_rollout %>%
mutate(treat_year = ifelse(cnt == 16, 'pre 1977', ifelse(cnt <= 16 & cnt > 0, 1992 - (cnt - 1), 0)))
state_rollout = state_rollout %>%
mutate(pre_treat = ifelse(treat_year == 'pre 1977',1,0))
rollout = state_rollout %>%
distinct(state, treat_year) %>%
arrange(treat_year)
pre_1977 = rollout %>%
filter(treat_year == 'pre 1977')
post_1977 = rollout %>%
filter(treat_year != 'pre 1977') %>%
filter(treat_year != 0)
rollout_table = rbind(pre_1977, post_1977)
kable(rollout_table, col.names = c("State", "Year"), caption = "Right-to-Carry Rollout")
#import modules
library(dplyr)
library(ggplot2)
library(rdrobust)
library(magrittr)
library(haven)
library(tidyverse)
library(data.table)
library(fixest)
library(glue)
library(data.table)
library(caret)
library(glmnet)
library(gbm)
library(ggmap)
library(rpart)
library(rpart.plot)
library(randomForest)
library(rsample)
library(modelr)
library(fastDummies)
library(scales)
library(here)
library(knitr)
library(kableExtra)
library(stargazer)
library(here)
library(foreach)
library(rddensity)
library(dplyr)
library(modelsummary)
path <- here()
# show p
plot(p)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
path<-here()
ABIA = read.csv("../data/ABIA.csv")
#average delay time based on airtime
AVG_Delay <- aggregate(DepDelay ~ AirTime, ABIA, mean)
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()
ABIA = read.csv("../data/ABIA.csv")
#average delay time based on airtime
AVG_Delay <- aggregate(DepDelay ~ AirTime, ABIA, mean)
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()
ABIA = read.csv("../data/ABIA.csv")
#average delay time based on airtime
AVG_Delay <- aggregate(DepDelay ~ AirTime, ABIA, mean)
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()+
ggtitle("Average Depature Delay based on Air Time")+
labs(y= "Depature Delay (minutes)", x = "Air Time (minutes")
ggplot(AVG_Delay, aes(x=AirTime, y=DepDelay))+
geom_line()+
ggtitle("Average Depature Delay based on Air Time")+
labs(y= "Depature Delay (minutes)", x = "Air Time (minutes)")
View(AVG_Delay)
View(ABIA)
olympics_top20=read.csv("../data/olympics_top20.csv")
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
quantile(olympics_top20$height, probs=0.95)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- quantile(olympics_top20$height, probs=0.95)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile(olympics_top20$height, probs=0.95))
View(df)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
dt <- data.frame(id = quantile_number, values = quantile(olympics_top20$height, probs=0.95))
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
dt <- data.frame(id = 'quantile_number', values = quantile(olympics_top20$height, probs=0.95))
View(dt)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(id = '95%', values = quantile(olympics_top20$height, probs=0.95))
View(df)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', values = quantile(olympics_top20$height, probs=0.95))
View(df)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE))
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(stargazer)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
kable(df, caption = "95th percentile of heights for female competitors")
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
view(df)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
kable(df[1, ], caption = 'heights for female competitors)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
kable(df, caption = 'heights for female competitors)
olympics_female<-olympics_top20 %>%
filter(sex =="F", sport=='Athletics') # filter female athletics
df <- data.frame(quantile_number = '95%', height = quantile(olympics_top20$height, probs=0.95), stringsAsFactors=FALSE)
kable(df, caption = 'heights for female competitors')
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(stargazer)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(stargazer)
library(knitr)
#Filter by female
olympics_female<-olympics_top20 %>%
filter(sex =="F")
#produce a sorted dataframe containing event and std dev
result<-split(olympics_female, olympics_female$event)%>%
lapply(., function(x)sd(x$height))%>%
unlist(.)%>%as.data.frame(.)
res<-cbind(row.names(result),result)
colnames(res)<-c("event","height_std_dev")
#sort by std_dev
res_order<-res[order(res$height_std_dev, decreasing = TRUE),]
head(res_order)
#Filter by female
olympics_female<-olympics_top20 %>%
filter(sex =="F")
#produce a sorted dataframe containing event and std dev
result<-split(olympics_female, olympics_female$event)%>%
lapply(., function(x)sd(x$height))%>%
unlist(.)%>%as.data.frame(.)
res<-cbind(row.names(result),result)
colnames(res)<-c("event","height_std_dev")
#sort by std_dev
res_order<-res[order(res$height_std_dev, decreasing = TRUE),]
res5 <- data.frame(head(res_order))
kable(res5, caption = 'Top 5 Female Events that Have the Greatest Variability in Height')
View(res_order)
#Filter by female
olympics_female<-olympics_top20 %>%
filter(sex =="F")
#produce a sorted dataframe containing event and std dev
result<-split(olympics_female, olympics_female$event)%>%
lapply(., function(x)sd(x$height))%>%
unlist(.)%>%as.data.frame(.)
res<-cbind(row.names(result),result)
colnames(res)<-c("event","height_std_dev")
#sort by std_dev
res5 <- data.frame(head(res[order(res$height_std_dev, decreasing = TRUE),]))
kable(res5, caption = 'Top 5 Female Events that Have the Greatest Variability in Height')
olympics_swimmer <- olympics_top20 %>%
filter(sport == 'Swimming')
#average age of swimmers over time
AVG_Age_Swimmer <- aggregate(age ~ year, olympics_swimmer, mean)
#average age of swimmers in different genders over time
AVG_Age_Gender <- aggregate(age ~ year + sex, olympics_swimmer, mean)
# linear graph
ggplot()+
geom_line(data = AVG_Age_Swimmer, aes(x=year, y=age))+
geom_smooth(span = 1)+
geom_line(data=AVG_Age_Gender, aes(x=year, y=age, color = sex))
cv_grid350 = foreach(k = k_grid, .combine='rbind') %dopar% {
# map the model-fitting function over the training sets
models = map(trim350_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
# map the RMSE calculation over the trained models and test sets simultaneously
errs = map2_dbl(models, trim350_folds$test, modelr::rmse)
c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds)) # approximate standard error of CV error
} %>% as.data.frame
# plot means and std errors versus k
ggplot(cv_grid350) +
geom_point(aes(x=k, y=err)) +
geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
scale_x_log10()
cv_grid350 = foreach(k = k_grid, .combine='rbind') %dopar% {
# map the model-fitting function over the training sets
models = map(trim350_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
# map the RMSE calculation over the trained models and test sets simultaneously
errs = map2_dbl(models, trim350_folds$test, modelr::rmse)
c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds)) # approximate standard error of CV error
} %>% as.data.frame
# plot means and std errors versus k
ggplot(cv_grid350) +
geom_point(aes(x=k, y=err)) +
geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
scale_x_log10()
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
sclass = read.csv('../data/sclass.csv')
trim_350 <- sclass %>%
filter(trim =='350') #filter 350
trim_65_AMG <- sclass %>%
filter(trim == '65 AMG') #filter AMG
# split testing and training dataset
trim_350_split =  initial_split(trim_350, prop=0.8)
trim350_train = training(trim_350_split)
trim350_test  = testing(trim_350_split)
trim_AMG_split = initial_split(trim_65_AMG, prop=0.8)
trimAMG_train = training(trim_AMG_split)
trimAMG_test = testing(trim_AMG_split)
# k-value cross validation
k_folds = 5
trim350_folds = crossv_kfold(trim_350, k=K_folds)
trimAMG_folds = crossv_kfold(trim_65_AMG,k=k_folds)
# define a series of k
k_grid = c(2, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
# knn to 350
knn15 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn15, trim350_test)
# attach the predictions to the test data frame
trim350_test = trim350_test %>%
mutate(Price_pred = predict(knn15, trim350_test))
p_test = ggplot(data = trim350_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
cv_gridAMG = foreach(k = k_grid, .combine='rbind') %dopar% {
# map the model-fitting function over the training sets
models = map(trimAMG_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
# map the RMSE calculation over the trained models and test sets simultaneously
errs = map2_dbl(models, trimAMG_folds$test, modelr::rmse)
c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds)) # approximate standard error of CV error
} %>% as.data.frame
# plot means and std errors versus k
ggplot(cv_gridAMG) +
geom_point(aes(x=k, y=err)) +
geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
scale_x_log10()
# knn to AMG
knn20 = knnreg(price ~ mileage, data=trim350_train, k=30)
modelr::rmse(knn20, trimAMG_test)
# attach the predictions to the test data frame
trimAMG_test = trimAMG_test %>%
mutate(Price_pred = predict(knn20, trimAMG_test))
p_test = ggplot(data = trimAMG_test) +
geom_point(mapping = aes(x = mileage, y = price), alpha=0.2)
# add the predictions
p_test + geom_line(aes(x = mileage, y = Price_pred), color='red', size=1.5)
